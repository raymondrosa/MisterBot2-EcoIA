Licencia: CC-NC; CÃ³digo de registro: 2602234666960; Prof. Raymond Rosa Ãvila

ğŸ¤– MisterBot2 â€“ Eco-IA

Asistente conversacional inteligente con memoria persistente, RAG (Retrieval-Augmented Generation) y procesamiento de documentos PDF utilizando modelos locales con Ollama.

Construido con:

Streamlit (Interfaz web)

LangChain (OrquestaciÃ³n LLM)

Ollama (Modelos locales)

ChromaDB (Vector Store persistente)

Embeddings locales

Memoria conversacional persistente en archivo .txt

ğŸš€ CaracterÃ­sticas

âœ… Modelos 100% locales (sin depender de APIs externas)

âœ… Sistema RAG sobre documentos PDF

âœ… VectorizaciÃ³n persistente con Chroma

âœ… Memoria de conversaciÃ³n guardada en archivo

âœ… Interfaz profesional con fondo personalizado y logo

âœ… Optimizado para bajo consumo (modelo cuantizado)

ğŸ§  Arquitectura del Sistema

Usuario â†’ Streamlit UI
â†“
ConversationalRetrievalChain
â†“
LLM (Ollama - llama3)
â†“
Chroma Vector Store
â†“
Embeddings (nomic-embed-text)
â†“
PDF Indexado

Memoria adicional:

memoria2/chat.txt

memoria2/vector_db/

ğŸ“¦ Requisitos Previos

Antes de instalar, asegÃºrate de tener:

Python 3.9 o superior

Ollama instalado

Git (opcional, pero recomendado)

ğŸ› ï¸ InstalaciÃ³n Paso a Paso
1ï¸âƒ£ Clonar el repositorio
git clone https://github.com/TU-USUARIO/MisterBot2.git
cd MisterBot2
2ï¸âƒ£ Crear entorno virtual

Windows:

python -m venv venv
venv\Scripts\activate

Mac / Linux:

python3 -m venv venv
source venv/bin/activate
3ï¸âƒ£ Instalar dependencias

Crear archivo requirements.txt con:

streamlit
langchain
langchain-community
langchain-experimental
chromadb
ollama
pypdf

Luego instalar:

pip install -r requirements.txt
4ï¸âƒ£ Instalar Ollama

Descargar desde:

https://ollama.com

Verificar instalaciÃ³n:

ollama --version
5ï¸âƒ£ Descargar los modelos necesarios

Tu aplicaciÃ³n usa:

llama3:8b-instruct-q4_0

nomic-embed-text

Instalarlos con:

ollama pull llama3:8b-instruct-q4_0
ollama pull nomic-embed-text

âš ï¸ Este paso es obligatorio.

6ï¸âƒ£ Verificar estructura del proyecto

Tu carpeta debe contener:

MisterBot2.py
documento.pdf
fondo.png
logo.png
memoria2/

Si no existe memoria2, el sistema la crea automÃ¡ticamente.

7ï¸âƒ£ Ejecutar la aplicaciÃ³n
streamlit run MisterBot2.py

Luego abrir en el navegador:

http://localhost:8501
ğŸ“ Estructura del Proyecto
MisterBot2/
â”‚
â”œâ”€â”€ MisterBot2.py
â”œâ”€â”€ documento.pdf
â”œâ”€â”€ fondo.png
â”œâ”€â”€ logo.png
â”œâ”€â”€ requirements.txt
â””â”€â”€ memoria2/
    â”œâ”€â”€ chat.txt
    â””â”€â”€ vector_db/
ğŸ§  Â¿CÃ³mo Funciona?

Si existe base vectorial â†’ la reutiliza.

Si no existe â†’ indexa el PDF automÃ¡ticamente.

Carga memoria previa desde chat.txt.

Cada pregunta:

Recupera contexto relevante

Genera respuesta

Guarda conversaciÃ³n

Mantiene ventana de memoria configurable (k=5).

ğŸ§ª SoluciÃ³n de Problemas
âŒ Error: No se pudo importar ConversationalRetrievalChain

La app incluye fallback automÃ¡tico para versiones distintas de LangChain.
Si persiste el error:

pip install --upgrade langchain langchain-community
âŒ Error: Ollama no estÃ¡ corriendo

Ejecutar:

ollama serve
âŒ No encuentra el PDF

Verifica que el archivo se llame exactamente:

documento.pdf
âš™ï¸ PersonalizaciÃ³n

Puedes modificar en el cÃ³digo:

MODEL_NAME = "llama3:8b-instruct-q4_0"
EMBED_MODEL = "nomic-embed-text"

TambiÃ©n puedes ajustar:

TamaÃ±o de chunks

NÃºmero de documentos recuperados (k)

Ventana de memoria conversacional

ğŸ” Licencia

Licencia Creative Commons CC-NC
Autor: Prof. Raymond Rosa Ãvila

ğŸŒ Futuras Mejoras (Roadmap)

Soporte para mÃºltiples PDFs

Memoria estructurada en JSON

Deploy en servidor Linux

DockerizaciÃ³n

IntegraciÃ³n con GitHub Pages (frontend ligero)

AutenticaciÃ³n multiusuario

Dashboard analÃ­tico de consultas

ğŸ§­ VisiÃ³n

MisterBot2 no es solo un chatbot.
Es un nÃºcleo cognitivo local, soberano y escalable.
Una plataforma base para asistentes especializados en ingenierÃ­a, educaciÃ³n e investigaciÃ³n cientÃ­fica.

El siguiente paso natural: contenerizarlo y desplegarlo en infraestructura cloud hÃ­brida.
